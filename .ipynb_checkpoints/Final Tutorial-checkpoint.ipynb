{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=\"Movie1.jpg\">\n",
    "<h1 style=\"line-height:15px;\"><center> Movie Industy and Gross Profit of a Movie </center></h1>\n",
    "<h3 style=\"line-height:5px;\"> Author:  Tianrui Guan, Xuejing Wang, Kaiyin Li </h3>\n",
    "<h6 style=\"line-height:1px;\"> Published: Dec 8, 2018 </h6>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "\n",
    "<ol style=\"font-size:115%;line-height:25px;\">\n",
    "    <li>\n",
    "        <strong>Introduction</strong>\n",
    "        <ul>\n",
    "            <li>Background and Motivation</li>\n",
    "            <li>About data</li>\n",
    "            <li>Relevant information</li><br>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        <strong>Data Scraping</strong>       \n",
    "    </li>\n",
    "    <li>\n",
    "        <strong>Data Wrangling</strong>\n",
    "        <ul>\n",
    "            <li>Data Cleaning</li>\n",
    "            <li>Missing data and Imputation</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        <strong>Data Visualization</strong>\n",
    "        <ul>\n",
    "            <li>Distrubution 1</li>\n",
    "            <li>Distrubution 2</li>\n",
    "            <li>Distrubution 3</li>\n",
    "            <li> ... </li><br>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        <strong>Cluster Analysis(T test)</strong>\n",
    "        <ul>\n",
    "            <li>Cluster 1</li>\n",
    "            <li>Cluster 2</li>\n",
    "            <li>Cluster 3</li>\n",
    "            <li> ... </li><br>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        <strong>Prediction</strong>\n",
    "        <ul>\n",
    "            <li>Prediction of gross profit of a movie</li>\n",
    "            <li>Prediction of gross profit of a movie company</li>\n",
    "            <li>Cluster 3</li>\n",
    "            <li> ... </li><br>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        <strong>Conclusions</strong>\n",
    "        <ul>\n",
    "            <li> Summary </li>\n",
    "            <li> Other Problems </li><br>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        <strong>appendix</strong>\n",
    "        <ul>\n",
    "            <li>Relevent resources</li>\n",
    "            <li>Sources files</li><br>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "### Background and Motivations\n",
    "\n",
    "From the exploration of data in previous projects, we realize how much we can learn from data and make conclusions from analized data. So we want to discuss something what is relavent to everyone, regardless of their interests. Entertainment is relavent to everyone's life, so we decided to explore data about it. At the same time, considering the accuracy of the data from the internet, it is hard to obtain accurate and relatively unbiased data from any websites about entertainment. After browsing many websites and sources, we targeted at Internet Movie Database ([IMDb](https://www.imdb.com/)). IMDb is an online database of information related to films, television programs, home videos and video games. According to wikipedia, IMDb has approximately 5.3 million titles (including episodes) as well as 83 million registered users before Octoer 2018. Because of the authority and completeness of IMDb, we decided to scrap data on the website, analyze the layout of the moive industry globally and try to make some prediction about an incoming movie.\n",
    "\n",
    "### About data\n",
    "The data was scrapped from [IMDb](https://www.imdb.com/). In the raw data, there are 7260 data points, including all of the movies from 1986 to 2018. Each movie has 13 attributes as following:\n",
    "<ul style=\"line-height:25px;\">\n",
    "    <li>Name: name of the movie</li>\n",
    "    <li>Year: year of release</li>\n",
    "    <li>Released: specific date of release</li>\n",
    "    <li>Genre: categories</li>\n",
    "    <li>Rating: content rating(some details)<br>\n",
    "         <ul>\n",
    "             <li>G: General Audiences</li>\n",
    "             <li>PG: Parental Guidance Suggested</li>\n",
    "             <li>PG-13: Special Guidance for Children Under 13</li>\n",
    "             <li>R: Accompanying of parent Under 17</li>\n",
    "             <li>Others: TV-PG, TV-14, TV-MA and NC-17</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Runtime: the length of the movie(in minutes)</li>\n",
    "    <li>Score: the score of the movie, from 0 to 10</li>\n",
    "    <li>Votes: the number of comments made regarding the movie</li>\n",
    "    <li>Companies: list of companies involved in the production</li>\n",
    "    <li>Country: the country that produced the movie</li>\n",
    "    <li>Language: the language used in the movie</li>\n",
    "    <li>Budget: budget of a movie</li>\n",
    "    <li>Gross: the profit of a movie, which is revenue minus the cost</li>\n",
    "</ul>\n",
    "\n",
    "Due to the fact that the data is huge, we scrapped it in the script and stored it in the csv file. But we also put our scrapping code in the notebook. \n",
    "\n",
    "### Relevant information\n",
    "\n",
    "The idea was inspired by a [dataset](https://www.kaggle.com/danielgrijalvas/movies) from kaggle about Movie Industry. But their data was out of date (with movies only before 2016) and some of the information was not captured (for some features like company and genre, only one of them was scrapped). Therefore, we decided to write the scrapping code and create our own dataset. We deleted and added a few columns that are relevant to our discussion, made sure that we included all informations we want, and added data from 2017 to 2018.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Scraping\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [IMDb](https://www.imdb.com/), we scrapped 7260 movie information. First, there are some necessary import and some helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary code for scrapping.\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home page of IMDb\n",
    "root = 'http://www.imdb.com'\n",
    "# format of the urls we are interested, passing in different years.\n",
    "url = ('http://www.imdb.com/search/title?count=220&view=simple'\n",
    "    '&boxoffice_gross_us=1,&title_type=feature&release_date={year}')\n",
    "# http header sent with the quests\n",
    "headers = {'Accept-Language': 'en-US'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful functions:\n",
    "\n",
    "# this function pass in a year as int, \n",
    "# and return a list of urls movies released in that year.\n",
    "def get_movies(year):\n",
    "    # request pages on that year.\n",
    "    movies_html = requests.get(url.format(year=year), headers=headers).content\n",
    "    # use beautiful soup to parse the page requested\n",
    "    soup = BeautifulSoup(movies_html, 'html.parser')\n",
    "    # find all of the links in the webpage regarding a movie\n",
    "    movies = soup.findAll('a', {'href': re.compile('adv_li_i$')})\n",
    "    # return a list of urls of this year.\n",
    "    return [root + m['href'] for m in movies]\n",
    "\n",
    "# pass in a full url about a movie, \n",
    "# and reutrn the content requested before parsed\n",
    "def go_to_movie(url):\n",
    "    movie_html = requests.get(url, headers=headers).content\n",
    "    return movie_html\n",
    "\n",
    "# pass in a full url about a production company, \n",
    "# and return the name of the company in string.\n",
    "# if the page is corrupted, or the connection has timeout,\n",
    "# return empty string\n",
    "def get_company(url):\n",
    "    # Due to internet issue, we try multiple times when we failed. \n",
    "    # (it happened and I'll have to parse the whole year again. \n",
    "    # To reduce the chances of failure, try many times before gave up)\n",
    "    for i in range(5):\n",
    "        # This is one of 7000 cases where the link doesn't work, \n",
    "        # so just return empty string\n",
    "        if '/company/co0677497/' in url:\n",
    "            return ''\n",
    "        try:\n",
    "            # scrap the name of the company\n",
    "            html = requests.get(url, headers=headers).content\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            company = soup.find(\"meta\",  property=\"og:title\")['content'].replace('With', '(').split('(')[1].strip()\n",
    "            return company\n",
    "        # catch connection error, and give up after five times.\n",
    "        except ConnectionError:\n",
    "            continue;\n",
    "    return ''\n",
    "\n",
    "# append a list of data into the file without index\n",
    "def write_csv(data):\n",
    "    df = pd.DataFrame(data)\n",
    "    # we stored the data in the file called movies_new.csv\n",
    "    df.to_csv('movies_new.csv', mode='a', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the page where we do most of the work for a movie.\n",
    "# we pass in a beautifulsoup object regarding a movie after\n",
    "# parsed by a html parser, as well as the current year we are parsing,\n",
    "# in case of we can not find year information in the webpage\n",
    "def scrap_details(soup, search_year):\n",
    "    # first we find a tag that includes a formatted json\n",
    "    details = soup.find(\"script\", type=\"application/ld+json\")\n",
    "    js = json.loads(details.text)\n",
    "    \n",
    "    # access name and genre fields\n",
    "    name = js['name']\n",
    "    genre = ','.join(js['genre'])\n",
    "\n",
    "    # The content rating of a movie,\n",
    "    try:\n",
    "        rating = js['contentRating']\n",
    "    except KeyError:\n",
    "        # if it is not given, use 'Not specified'.\n",
    "        rating = 'Not specified'\n",
    "        \n",
    "    # find duration of the movie\n",
    "    try:\n",
    "        runtime = int(soup.find('h4', string='Runtime:').parent.contents[3].text[:-3].strip())\n",
    "    except AttributeError:\n",
    "        # if we can't, use another field and parse the string mannually\n",
    "        time = re.findall(r'\\d+', js['duration'])\n",
    "        if len(time) > 1:\n",
    "            runtime = 60 * int(time[0]) + int(time[1])\n",
    "        else: \n",
    "            runtime = 60 * int(time[0])\n",
    "    # find the release year and date\n",
    "    try:\n",
    "        year = js['datePublished'][:4]\n",
    "        released = js['datePublished']\n",
    "    except KeyError:\n",
    "        # if it is not in the json format, use a string passed in \n",
    "        # and use 'Not specified' on the date.\n",
    "        # note that sometimes the release year may differ from the year \n",
    "        # show up in the search page, so I use the year in the \n",
    "        # web search only if we can not find publish date about the movie\n",
    "        year = str(search_year)\n",
    "        released = 'Not specified'\n",
    "\n",
    "    # the rating of the movie and how many comments it has\n",
    "    score = float(js['aggregateRating']['ratingValue'])\n",
    "    votes = int(js['aggregateRating']['ratingCount'])\n",
    "    \n",
    "\n",
    "    \n",
    "    try:\n",
    "        # get list of suffixes about url of a company\n",
    "        companies_url = [ c['url'] for c in js['creator'] if c['@type'] == 'Organization' ]\n",
    "        if companies_url:\n",
    "            # if the list is not empty, then connect them with ',',\n",
    "            # use get_company and store the company name (make sure to exclude empty string)\n",
    "            companies = ','.join([ u for u in [ get_company(root+c_url) for c_url in companies_url ] if u != ''])\n",
    "        else:\n",
    "            # if it is empty, it means the creator is not specified, or all of the creation\n",
    "            # and production was done by individuals\n",
    "            companies = 'Personal'\n",
    "    except TypeError:\n",
    "        # if the result was not well-formatted (specifically, when there is only one creator,\n",
    "        # the field was no longer a list, so just access the element directly.)\n",
    "        if js['creator']['@type'] == 'Organization':\n",
    "            companies = get_company(root+js['creator']['url'])\n",
    "        else:\n",
    "            companies = 'Personal'\n",
    "\n",
    "    # locate the information about country and language in the beautifulsoup object\n",
    "    country = soup.find('a', {'href': re.compile('country_of_origin')}).text\n",
    "    language = ','.join(l.text for l in soup.find_all('a', {'href': re.compile('primary_language')}) )\n",
    "\n",
    "    # find the budget field and convert it to float\n",
    "    try:\n",
    "        budget = soup.find('h4', string='Budget:').parent.contents[2].strip()\n",
    "        if not '$' in budget:\n",
    "            # in case the field was not well formatted\n",
    "            budget = 'Not specified'\n",
    "        else:\n",
    "            budget = float(budget.replace('$','').replace(',',''))\n",
    "    except AttributeError:\n",
    "        # if we can not find budget information\n",
    "        budget = 'Not specified'\n",
    "\n",
    "    # find gross profit in the website, using either Cumulative Worldwide Gross\n",
    "    # or Gross USA, whichever is available\n",
    "    try:\n",
    "        gross = soup.find('h4', string='Cumulative Worldwide Gross:').parent.contents[2].strip()[:-1]\n",
    "        gross = float(gross.replace('$','').replace(',',''))\n",
    "    except (AttributeError, ValueError):\n",
    "        try:\n",
    "            gross = soup.find('h4', string='Gross USA:').parent.contents[2].strip()[:-1]\n",
    "            gross = float(gross.replace('$','').replace(',',''))\n",
    "        except (AttributeError, ValueError):\n",
    "            gross = 'Not specified'\n",
    "    # return all of the data about the movie\n",
    "    data_line = {'name': name, 'rating': rating, 'genre': genre, 'runtime': runtime, 'year': year, \n",
    "                 'released': released, 'score': score, 'votes': votes, 'rating': rating, 'companies': companies, \n",
    "                 'country': country, 'language': language, 'budget': budget, 'gross': gross}\n",
    "\n",
    "    return data_line\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the main function in the script, to make sure it will not run,\n",
    "# we left it in the main function.\n",
    "\n",
    "def main():\n",
    "    # from 1986 to 2018\n",
    "    for year in range(1986, 2019):\n",
    "        data = []\n",
    "        # get all of the urls of movies in this year\n",
    "        movies = get_movies(year)\n",
    "\n",
    "        for movie_url in movies:\n",
    "            # for each movie, I print out the informations for debuggging purpose\n",
    "            print(year, '&', movie_url)\n",
    "            movie_data = {}\n",
    "            # get html text and use html parser to parse it\n",
    "            movie_html = go_to_movie(movie_url)\n",
    "            soup = BeautifulSoup(movie_html, 'html.parser')\n",
    "            \n",
    "            # scrap data and put it in the yearly data.\n",
    "            movie_data.update(scrap_details(soup, year))\n",
    "            data.append(movie_data)\n",
    "        # For every year, we append all of the information once to the movie and show a prompt\n",
    "        # Note that since we don't have an id for a movie, so there is not way\n",
    "        # to start where we left off when the program breaks due to a bug. \n",
    "        # we can only start from scratch at different years when that happened.\n",
    "        write_csv(data)\n",
    "        print(year, 'done.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, even if we parser our own data, we can not expect that our data is nice and clean. So we need to look at the data and clean it up for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Wrangling\n",
    "### Data Cleaning\n",
    "At this step, we need to look at our data and clean it up. First import necessary tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas for dataframe\n",
    "import pandas as pd\n",
    "# linear algebra\n",
    "import numpy as np\n",
    "# and read in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then remove some repetitive rows of features resulted from appending data each year, change string about date into datetime object and reorganize the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>released_date</th>\n",
       "      <th>genre</th>\n",
       "      <th>rating</th>\n",
       "      <th>runtime</th>\n",
       "      <th>score</th>\n",
       "      <th>votes</th>\n",
       "      <th>companies</th>\n",
       "      <th>country</th>\n",
       "      <th>language</th>\n",
       "      <th>budget</th>\n",
       "      <th>gross</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top Gun</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-05-16</td>\n",
       "      <td>Action,Drama</td>\n",
       "      <td>PG</td>\n",
       "      <td>110</td>\n",
       "      <td>6.9</td>\n",
       "      <td>254409</td>\n",
       "      <td>Paramount Pictures,Don Simpson/Jerry Bruckheim...</td>\n",
       "      <td>USA</td>\n",
       "      <td>English</td>\n",
       "      <td>15000000.0</td>\n",
       "      <td>35683060.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aliens</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-07-18</td>\n",
       "      <td>Action,Adventure,Sci-Fi,Thriller</td>\n",
       "      <td>R</td>\n",
       "      <td>137</td>\n",
       "      <td>8.4</td>\n",
       "      <td>582947</td>\n",
       "      <td>Twentieth Century Fox,Brandywine Productions,S...</td>\n",
       "      <td>USA</td>\n",
       "      <td>English</td>\n",
       "      <td>18500000.0</td>\n",
       "      <td>13106024.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Highlander</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-03-07</td>\n",
       "      <td>Action,Adventure,Fantasy</td>\n",
       "      <td>R</td>\n",
       "      <td>116</td>\n",
       "      <td>7.2</td>\n",
       "      <td>110612</td>\n",
       "      <td>Thorn EMI Screen Entertainment,Highlander Prod...</td>\n",
       "      <td>UK</td>\n",
       "      <td>English</td>\n",
       "      <td>16000000.0</td>\n",
       "      <td>1288519.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stand by Me</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-11-04</td>\n",
       "      <td>Adventure,Drama</td>\n",
       "      <td>R</td>\n",
       "      <td>89</td>\n",
       "      <td>8.1</td>\n",
       "      <td>324695</td>\n",
       "      <td>Columbia Pictures Corporation,Act III,Act III ...</td>\n",
       "      <td>USA</td>\n",
       "      <td>English</td>\n",
       "      <td>8000000.0</td>\n",
       "      <td>5228741.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ferris Bueller's Day Off</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-06-11</td>\n",
       "      <td>C,o,m,e,d,y</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>103</td>\n",
       "      <td>7.8</td>\n",
       "      <td>281414</td>\n",
       "      <td>Paramount Pictures</td>\n",
       "      <td>USA</td>\n",
       "      <td>English,German</td>\n",
       "      <td>6000000.0</td>\n",
       "      <td>7013636.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  year released_date  \\\n",
       "0                   Top Gun  1986    1986-05-16   \n",
       "1                    Aliens  1986    1986-07-18   \n",
       "2                Highlander  1986    1986-03-07   \n",
       "3               Stand by Me  1986    1986-11-04   \n",
       "4  Ferris Bueller's Day Off  1986    1986-06-11   \n",
       "\n",
       "                              genre rating runtime score   votes  \\\n",
       "0                      Action,Drama     PG     110   6.9  254409   \n",
       "1  Action,Adventure,Sci-Fi,Thriller      R     137   8.4  582947   \n",
       "2          Action,Adventure,Fantasy      R     116   7.2  110612   \n",
       "3                   Adventure,Drama      R      89   8.1  324695   \n",
       "4                       C,o,m,e,d,y  PG-13     103   7.8  281414   \n",
       "\n",
       "                                           companies country        language  \\\n",
       "0  Paramount Pictures,Don Simpson/Jerry Bruckheim...     USA         English   \n",
       "1  Twentieth Century Fox,Brandywine Productions,S...     USA         English   \n",
       "2  Thorn EMI Screen Entertainment,Highlander Prod...      UK         English   \n",
       "3  Columbia Pictures Corporation,Act III,Act III ...     USA         English   \n",
       "4                                 Paramount Pictures     USA  English,German   \n",
       "\n",
       "       budget       gross  \n",
       "0  15000000.0  35683060.0  \n",
       "1  18500000.0  13106024.0  \n",
       "2  16000000.0   1288519.0  \n",
       "3   8000000.0   5228741.0  \n",
       "4   6000000.0   7013636.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the csv file\n",
    "data = pd.read_csv('./movies_new.csv')\n",
    "# When appending to the file at each yaer iteration, we repetitively added\n",
    "# the columns features to the data. So we need to remove those\n",
    "data = data[data.name != 'name']\n",
    "# replace missing data with np.nan\n",
    "data.replace(['Unrated', 'Not Rated', 'Not specified'], np.nan, inplace=True)\n",
    "# converting time to datetime object\n",
    "data['released_date'] = pd.to_datetime(data.released)\n",
    "# reorganize columns\n",
    "order = ['name', 'year', 'released_date', 'genre', 'rating', 'runtime', 'score',\n",
    "         'votes', 'companies', 'country', 'language', 'budget', 'gross']\n",
    "data = data[order]\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how many percent each feature are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data and Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# for data analysis\n",
    "from sklearn import preprocessing\n",
    "from sklearn import datasets\n",
    "from scipy import stats\n",
    "\n",
    "# for data visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# note that: see companies: Personal & Not specified.\n",
    "# temp = [d for d in data.released if '-' not in d]\n",
    "# temp\n",
    "# data.set_index('name')\n",
    "# data[data.duplicated()]\n",
    "\n",
    "# data.drop_duplicates(subset='released')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
